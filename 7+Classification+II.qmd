---
title: "Classification II"

#editor: visual
---

[üõ°Ô∏èLecture link](https://andrewmaclachlan.github.io/CASA0023-lecture-7/#1)<br/> [‚öîÔ∏èPractical link](https://andrewmaclachlan.github.io/CASA0023/7_classification_II.html)<br/>

<img src="https://raw.githubusercontent.com/Murphy829/RSETEST/aa347d29a18cf725c9d4d39b472651edd5d73028/imgs/mindmaps/7%2BClassification%2BII.svg" width="700"/><br/> A mindmap for this chapter, marking orange is the part that works best for me.

## Summary

This week introduces a third image classification algorithm, Object-Based Image Analysis (OBIA), and how to determine the accuracy of the results against the classification.


### Object-Based Image Analysis (OBIA)



<img src="https://gisgeography.com/wp-content/uploads/2017/05/OBIA-segmentation-850x370.png"/ width=700><br/>
(Object-Based Image Analysis (OBIA) segmentation is a process that groups similar pixels into objects, Source:[GISGeography](https://gisgeography.com/obia-object-based-image-analysis-geobia/))

<img src="https://gisgeography.com/wp-content/uploads/2017/06/OBIA-classification1-1-850x370.png"/ width=700><br/>
(OBIA classification uses shape, size, and spectral properties of objects to classify each object, Source:[GISGeography](https://gisgeography.com/obia-object-based-image-analysis-geobia/))

- Instead of considering cells we consider shapes based on the similarity (homogeneity) or difference (heterogeneity) of the cells = superpixels

- OBIA classifies images into vector objects based on geometry, area, colour, shape, texture, proximity and other elements. This segmentation model is closer to the way human vision works and can overcome some of the problems associated with the traditional image model of pixel-based target classification, such as the "salt-and-pepper effect".

*"salt-and-pepper effect" is caused by high local spatial heterogeneity between neighboring pixels.([Kelly et al., 2011](https://www.researchgate.net/figure/Example-of-the-speckle-or-the-salt-and-pepper-effect-common-to-pixel-based_fig1_236334092))

- OBIA consists of two major stages:
  - Segmentation - partition of space to identify homogeneous objects
  - Classification - classification of the obtained objects

[Jakub Nowosad, 2021. Spatial segmentation in R
using the supercells package](https://jakubnowosad.com/ogh2021/#1)

```{=html}
<iframe width="700" height="500" src="https://jakubnowosad.com/ogh2021/#1" title="Spatial segmentation in R
using the supercells package"></iframe>
```


### Sub pixel analysis

- Termed (all the same): Sub pixel classification, Spectral Mixture Analysis (SMA), Linear spectral unmixing. SMA determines the proportion or abundance of landcover per pixel<br/>

<img src="https://www.researchgate.net/profile/Reinaldo-Perez-Machado/publication/259715697/figure/fig6/AS:667126004215814@1536066642302/Perfect-decomposition-with-a-Linear-Spectral-Mixture-Model-LSMM-on-a-30-m-pixel-formed.png"/ width=500><br/>
(Perfect decomposition with a Linear Spectral Mixture Model (LSMM) on a 30 m pixel formed by a mixture of 3 components: vegetation, water and soil. On this case the residual is zero., Source:[Machado and Small (2013) 2017](https://www.researchgate.net/figure/Perfect-decomposition-with-a-Linear-Spectral-Mixture-Model-LSMM-on-a-30-m-pixel-formed_fig6_259715697))


### Accuracy assessment

- Confusion matrix
<img src="https://github.com/Murphy829/RSETEST/blob/main/imgs/CMARTIX.png?raw=true"/ width=500><br/>
(Source:[Barsi et al. 2018 Accuracy Dimensions in Remote Sensing](https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-3/61/2018/isprs-archives-XLII-3-61-2018.pdf))

**There are many different ways to look at the thematic accuracy of a classification. The error matrix allows you calculate the following accuracy metrics:**

<img src="http://gsp.humboldt.edu/olm/Courses/GSP_216/images/error-matrix.png"/ width=500><br/>


- **PA Producer accuracy**

Producer's Accuracy is the map accuracy from the point of view of the map maker (the producer). This is how often are real features on the ground correctly shown on the classified map or the probability that a certain land cover of an area on the ground is classified as such. The Producer's Accuracy is complement of the Omission Error, Producer's Accuracy = 100%-Omission Error. It is also the number of reference sites classified accurately divided by the total number of reference sites for that class.

- **UA User‚Äôs accuracy**

The User's Accuracy is the accuracy from the point of view of a map user, not the map maker. the User's accuracy essentially tells use how often the class on the map will actually be present on the ground. This is referred to as reliability. The User's Accuracy is complement of the Commission Error, User's Accuracy = 100%-Commission Error. The User's Accuracy is calculating by taking the total number of correct classifications for a particular class and dividing it by the row total.

- **OA the (overall) accuracy**

Overall Accuracy is essentially tells us out of all of the reference sites what proportion were mapped correctly. The overall accuracy is usually expressed as a percent, with 100% accuracy being a perfect classification where all reference site were classified correctly. Overall accuracy is the easiest to calculate and understand but ultimately only provides the map user and producer with basic accuracy information.

- Errors of omission (100-producer's accuracy)

Errors of omission refer to reference sites that were left out (or omitted) from the correct class in the classified map. The real land cover type was left out or omitted from the classified map. Error of omission is sometime also referred to as a Type I error. An error of omission in one category will be counted as an error in commission in another category. Omission errors are calculated by reviewing the reference sites for incorrect classifications. This is done by going down the columns for each class and adding together the incorrect classifications and dividing them by the total number of reference sites for each class. A separate omission error is generally calculated for each class. This will allow us to evaluate the classification accuracy and error for each class.

- Errors of commission (100- user's accuracy)

Errors of omission are in relation to the classified results. These refer sites that are classified as to reference sites that were left out (or omitted) from the correct class in the classified map. Commission errors are calculated by reviewing the classified sites for incorrect classifications. This is done by going across the rows for each class and adding together the incorrect classifications and dividing them by the total number of classified sites for each class.

- Kappa coefficien: Designed to express the accuracy of an image compared to the results by chance

The Kappa Coefficient is generated from a statistical test to evaluate the accuracy of a classification. Kappa essentially evaluate how well the classification performed as compared to just randomly assigning values, i.e. did the classification do better than random. The Kappa Coefficient can range from -1 t0 1. A value of 0 indicated that the classification is no better than a random classification. A negative number indicates the classification is significantly worse than random. A value close to 1 indicates that the classification is significantly better than random.

(Source: [humboldt](http://gsp.humboldt.edu/olm/Courses/GSP_216/lessons/accuracy/metrics.html))

- F1-Score

The F1-Score (or F Measure) combines both recall (Producer accuracy) and Precision (User accuracy).


- Receiver Operating Characteristic Curve (the ROC Curve)

### Remote sensing approach

- Same process for all:

    - class definition
    - pre-processing
    - training
    - pixel assignment
    - accuracy assessment
    
### spatial autocorrelation

- Spatial cross validation
  - spatially partition the folded data, folds are from cross validation

  - disjoint (no common boundary) using k -means clustering (number of points and a distance)

  - same as cross validation but with clustering to the folds...

  - stops our training data and testing data being near each other...
  
<img src="https://r.geocompx.org/figures/13_partitioning.png"/ width=700><br/>
(Spatial visualization of selected test and training observations for cross-validation of one repetition. Random (upper row) and spatial partitioning (lower row). Source:[Lovelace et al. 2022](https://r.geocompx.org/spatial-cv.html))


## Application

- Urban Object-Based Classification

Land-use/land-cover (LULC) information extraction is one of the main use cases of remote sensing imagery. The advent of sub-meter resolution data brought about the revolution of methods from pixel-based to object-based image analysis (OBIA) involving image segmentation. (Source: [Grippa  et al., 2017](https://www.mdpi.com/2072-4292/9/4/358#))

<img src="https://pub.mdpi-res.com/remotesensing/remotesensing-09-00358/article_deploy/html/images/remotesensing-09-00358-ag.png?1569299358"/ width=700><br/>





## Reflection

These two weeks of learning about image classification and accuracy assessment, combined with the image correction and enhancement operations of the previous weeks, make up the complete remote sensing data classification process.

<img src="https://www.researchgate.net/publication/344052292/figure/fig1/AS:1083908439449624@1635435318887/Classification-process-of-remote-sensing-hyperspectral-images.jpg"/ width=700> <br/>
(Classification process of remote-sensing hyperspectral images.[Li et al.,2020](https://www.hindawi.com/journals/cin/2020/8886932/))



